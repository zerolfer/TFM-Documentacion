%! Suppress = MathOperatorEscape
%! Suppress = LabelConvention
%! Suppress = LineBreak
%! Suppress = UnresolvedReference
\NOTE{REVISAR GRAMÁTICA Y ORTOGRAFÍA A PARTIR DE AQUÍ!! \\
\NEW{A PARTIR DE ÉSTE PUNTO, TODO ES NUEVO}} %TODO NOTE
\subsection{Fase 2: Metaheurística de optimización multiobjetivo} \label{sec:3:metaheurística}
Se trata del núcleo principal del presente proyecto, pues trata de dar solución al problema en sí mediante un enfoque de metaheurísticas.

Como ya se ha introducido previamente, estamos ante un problema de \textit{timetabling/scheduling} que son generalmente problemas complejos debido a su naturaleza combinatoria. 
Matemáticamente se dice que pertenecen al conjunto de los problemas llamados \textit{NP-Duros (NP-Hard)}, pues los algoritmos clásicos empleados para resolverlos tienen una complejidad al menos de tipo exponencial.
Clásicamente se han empleado algoritmos para problemas concretos de este tipo que van desde el \textit{General Scheduling Problem} (GSP) que es el caso más general hasta los casos más concretos mediante variaciones respecto al anterior, haciéndolo más o menos restrictivo.
Algunos son: el \textit{Open Shop Scheduling} (OSS), \textit{Job Shop Scheduling} (JSS), \textit{Flow Shop Scheduling} (FSS) o \textit{Permutational Flow Shop Scheduling} (PFSS). Una clasificación más detallada de este tipo de problemas clásicos se encuentra en~\cite{sota:tesis-doctoral}. 

Lejos del entorno académico, los problemas reales de \textit{scheduling} (como el que tenemos entre manos en esta tesis) pueden ser muy diferentes entre sí, habiendo pues mucha variedad en función del ámbito de aplicación. 
Por ejemplo se han estudiado casos para transporte público~\cite{sota:transporte-publico} o universidades~\cite{sota:universidad} y podemos ver cómo son completamente diferentes en cuanto a restricciones y necesidades de cada una de las soluciones, por lo que las metodologías empleadas para su resolución son bien diferentes.

Existen gran cantidad de técnicas que se han empleado previamente para resolver este tipo de problemas, comenzando por sencillos heurísticos aplicados a los problemas clásicos bien estudiados y formalizados, pero como hemos puntualizado antes, este tipo de algoritmos solamente son aplicables a instancias pequeñas debido a la mencionada naturaleza no polinómica, por lo que no son útiles en problemas reales. Por otro lado, se ha analizado cómo transformar un problema de \textit{scheduling} en un problema de coloreado de grafos~\cite{sota:estudio-coloreado-grafos, sota:algotimo-coloreado-grafos} lo que nos permite emplear los algoritmos existentes para este tipo de problemas, entre los que podemos encontrar exactos y aproximados. También existen enfoques más modernos que emplean técnicas de \textit{Aprendizaje Automático} habitualmente combinados con metaheurísticas~\cite{sota:machine-learning-geneticos} y recientemente \textit{Hiperheurísticas} (como por ejemplo en~\cite{sota:hiperheuristicas}). En el libro~\cite{sota:libro-sota-scheduling} se encuentran explicadas de forma detallada todas estas técnicas aquí nombradas.

Por último, la técnica más empleada actualmente para resolver este tipo de problemas son las metaheurísticas: una familia de algoritmos de carácter genérico empleados como \textit{framework} para resolver un problema dado. Tienen dos características principales~\cite{sota:metaheuristicas}:

\begin{enumerate}
	\item En contraposición a los heurísticos, no dependen directamente del problema específico, únicamente han de ser adaptados parcialmente.
	\item Por definición son métodos de búsqueda aproximados, que tratan de combinar técnicas de exploración y explotación (véase \autoref{capitulo:3:busqueda-divers-intens}) para obtener la mejor solución posible dentro del espacio de búsqueda definido.
\end{enumerate}

Tienen dos conceptos básicos que conforman la clave para su implementación para un problema concreto: la función objetivo y la codificación. 

La codificación permite representar una solución de la forma más compacta posible sin perder información del dominio. Una buena codificación tendrá las siguientes características~\cite{sota:metaheuristicas-design-impl}:

\begin{itemize}
	\item Completitud: Todas las soluciones asociadas con el problema deben poder ser representadas. Se debe garantizar una representatividad total dentro del espacio de soluciones: si no es definida correctamente podría haber soluciones incapaces de ser representadas y lógicamente afectará a la eficiencia de la metaheurística.
	\item Conectividad: Debe existir un camino que permita moverse entre dos soluciones del espacio de búsqueda, de forma que cualquier solución del espacio pueda ser alcanzada (en especial el optimo global).
	\item Eficiencia: Fácil de manipular por los operadores de la búsqueda (definidos por cada metaheurística).
\end{itemize}

Por su parte, la función objetivo o de evaluación (en inglés denominada \textit{fitness}) permite la comparación de soluciones entre sí y representará el objetivo de la búsqueda, de forma que si nos enfrentamos a un problema con varios parámetros objetivo, podamos ponderarlos u ordenarlos según los criterios que se adecuen al problema. Existen varios enfoques para definir una función de evaluación de un problema multiobjetivo: enfoques escalares, basados criterios, basados en dominaciones (óptimos de Pareto) entre las soluciones o basados en indicadores de calidad. Los más sencillos son los primeros, pues permiten trasformar el problema multiobjetivo en uniobjetivo y al ser el empleado en esta tesis será descrito con mayor detenimiento en el \autoref{apartado:adaptacion-fitness}

Un problema de optimización multiobjetivo es de la siguiente forma:
%\[
\begin{flalign*}
	& \max_x \quad \textbf{f(x)} = \left( \, f_1(\textbf{x}), f_2(\textbf{x}), f_3(\textbf{x}), \dots, f_n(\textbf{x}) \, \right) \\
	& \; \text{s.a.} \quad \textbf{x} \in X
\end{flalign*}
%\]
Siendo $X$ en conjunto de soluciones factibles, definido mediante una serie de restricciones dadas por el dominio del problema.

Por otro lado, las metaheurísticas emplean una o varias soluciones que son comparadas entre sí empleando una función de comparación o evaluación  que suele ser de un coste computacional importante. Ésta función será dependiente del problema a resolver.

Estas técnicas fueron muy innovadoras, pues permitieron la resolución de muchos problemas clásicos que hasta entonces no podían resolverse con técnicas clásicas. Además, soportan perfectamente instancias grandes, por lo que hasta la fecha es la técnica más prometedora para el problema a resolver en esta tesis.

No obstante, la mayor desventaja de las metaheurísticas es que, al tratarse de métodos aproximados, no garantizan que se encuentre una solución óptima global ni que se encuentre acotada en algún rango de valores~\cite{sota:metaheuristicas-design-impl} como sí permiten otras técnicas. Una pequeña desventaja frente a todas las posibilidades que las metaheurísticas nos ofrecen.
 
Una vez decidida la técnica a emplear para resolver el problema definido, el siguiente paso es elegir de entre el catálogo de metaheurísticas existentes hasta la fecha, una de ellas. A lo largo del tiempo se han ido proponiendo diferentes taxonomías para ordenar toda esta gran cantidad de metaheurísticas. 
Así, una de las clasificaciones más conocidas es la propuesta por Osman en~\cite{metaheuristicas:taxonomia1} que distingue entre aquellas basadas en búsquedas locales (pequeños cambios a una misma solución), las constructivas (en cada iteración se van añadiendo partes que al final conforman una solución al completo) y las poblacionales (se combinan varias soluciones entre sí). 

Gendreau y Potvin~\cite{metaheuristicas:taxonomia2} propusieron en 2005 una clasificación dicotómica: aquellas de tipo trayectorial y de tipo poblacional, combinando así las de búsqueda local y las constructivas en un mismo grupo que emplea unicamente una sola solución por iteración mientras que las segundas emplean un conjunto dinámico de soluciones que en cada iteración irá cambiando. 

Existen otras clasificaciones menos relevantes que dividen las metaheurísticas en aquellas inspiradas en la naturaleza y aquellas que no, en si emplean capacidad de memoria o no, o si son de naturaleza determinista o estocástica. Una de las últimas clasificaciones~\cite{sota:metaheuristicas} propone la división en metafóricas (metáforas de la biología, química, música, matemáticas, física o social-deportiva) o no metafóricas.

En el caso de este proyecto, la elección fue de carácter histórica: los proyectos previos habían empleado dos metaheurísticas y una de ellas parecía dar resultados más prometedores que la otra. Estamos hablando de la metaheurística \textit{Variable Neighborhood Search} (\textit{Búsqueda de Entornos Variable}) que describiremos en las próximas secciones y veremos cómo ha sido adaptada a nuestro problema.

\subsubsection{Búsqueda en Entornos Variables (VNS)}
Se trata de una metaheurística trayectorial, pues maneja una única solución en cada iteración, además de tipo búsqueda local pues trata de modificarla iterativamente para mejorarla empleando un catálogo de \textit{entornos} o vecindades (\textit{neighborhoods}). A su vez es de tipo no metafórica: no se inspira en ningún proceso de la naturaleza. Es además de tipo estocástico y no emplea memoria para su funcionamiento.

Su nombre radica precisamente en sus dos conceptos fundamentales: búsqueda local y entornos variables. Se fundamenta en dos etapas~\cite{vns}: descenso y perturbación, la primera consiste en el intercambio sistemático del entorno empleado durante una búsqueda local simple que nos permite alcanzar un óptimo local; mientras que la segunda radica en la alteración aleatoria de la solución para evitar atascarse en óptimos locales evitando así una convergencia prematura.

Así pues, el VNS parte de una lista predefinida de entornos, que definen el criterio a emplear para moverse entre soluciones a partir de una inicial. Al entorno $k$ del conjunto de vecindades se les suele denotar como $N_k, k=1,\dots,k_{max}$ y al conjunto de soluciones alcanzables mediante la vecindad $k$ como $N_k(x)$.
Un ejemplo sencillo de entorno podría ser en el caso de una optimización de una variable en el dominio $\mathbb{R}$: un posible entorno sería $N_1=[x-2, x+2]$ o $N_2=[x-7, x+7]$, ilustrados en la \autoref{fig:ejemplos-entorno}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{ejemplos-entorno}
	\caption{Ejemplo de dos entornos definidos en $\mathbb{R}$}
	\label{fig:ejemplos-entorno}
\end{figure}

Como podemos observar, los entornos se definen con respecto a una solución, denotada por $x$. En el ejemplo los entornos se han definido de forma que el conjunto de soluciones alcanzables mediante el segundo sea un superconjunto del aquel empleando el primero, ampliando de esta forma las fronteras de la búsqueda (no es necesario definirlos así pero suele ser una práctica habitual). Si lanzamos una búsqueda local sobre la función del ejemplo empleando el entorno $k_1$, el punto más optimo que podemos alcanzar en caso de maximización es el punto $A$, mientras que si empleamos el $k_2$ será el $B$. El punto $C$ es el óptimo global de la función, que no es alcanzado por ninguno de los entornos definidos, aunque $k_2$ se aproxima bastante. 

No necesariamente un entorno amplio, i.e.\ con mayor conjunto de soluciones factibles, es mejor que uno más reducido, pues el espacio de búsqueda es mayor y esto repercutirá decisivamente en el rendimiento del algoritmo de búsqueda. Además, en problemas más complejos con un mayor número de variables, el espacio de búsqueda es mucho más complejo y difícil de explorar.

Con todo, el VNS se basa en tres caraterísticas:

\begin{enumerate}
	\item Un óptimo local respecto a una estructura de vecindad no necesariamente lo es respecto a otra.
	\item Un óptimo global es a su vez óptimo local respecto a todas las posibles estructuras de entornos.
	\item Empíricamente se ha determinado que para la mayoría de problemas, los óptimos locales con la misma o distinta estructura de entornos están relativamente cerca.
\end{enumerate}

En la \autoref{fig:VNS-facts} se ilustran estas tres características visualmente.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{VNS-facts}
	\caption[Ilustración que representa las características sobre las que se fundamenta el VNS]{Ilustración que representa las características sobre las que se fundamenta el VNS. Imagen proporcionada por Adolfo Urrutia Zambrana}
	\label{fig:VNS-facts}
\end{figure}

Comenzaremos analizando el cambio entre entornos, que se lleva a cabo de la misma forma en todo VNS siguiendo el \autoref{algoritmo:VNS-cambio-entornos}. 
Como se puede observar, se llevan a cabo acciones diferentes en función de si la nueva solución obtenida por el algoritmo de búsqueda local es mejor que la de partida. La función fitness se ha denotado como $f(x) \in [0,1]$

\begin{algorithm}[htbp]
	\caption{Algoritmo del VNS empleado para el cambio de vecindades en caso de un problema de maximización}
	\label{algoritmo:VNS-cambio-entornos}

	\DontPrintSemicolon
	\KwData{
		
		$x$, solución actual. En la primera iteración es la inicial.
				
		$x'$, solución obtenida del algoritmo de búsqueda local con el entorno $k$
		
		$k$, indice de la vecindad actual
	}
	\medskip

	\If{$f(x')>f(x)$}{
		$x \leftarrow x'$  \Comment{Moverse a la mejor solucion}
		$k \leftarrow 1$  \Comment{Reinicio de vecindades}
	}
	\Else{
		$k \leftarrow k+1$  \Comment{Siguiente vecino}
	}
	

\end{algorithm}

En cuanto al comportamiento de la búsqueda, el VNS en su versión básica (conocido como \textit{Basic VNS}) se compone de dos fases: la búsqueda local y la ``agitación`` (\textit{shake}) siendo la primera determinista y la segunda estocástica. Una componente aleatoria aporta nueva información a la búsqueda que podría ser de ayuda a la componente determinista.

La componente de búsqueda local se puede realizar en dos enfoques diferentes: buscando la primera solución que mejore la actual (\textit{First Improvement}) o empleando la mejor de todas las posibles soluciones del entorno (\textit{Best Improvement}) sin embargo no siempre es posible obtener todas las soluciones posibles de un entorno, especialmente en problemas complejos como el que tenemos entre manos. En éste problema se ha empleado una técnica mixta que si bien no emplea la mejor solución, tampoco emplea la primera mejor, sino que continúa la búsqueda hasta que la solución no se mejore en un porcentaje de tolerancia (véase \NOTE{REFERENCIA} para una descripción detallada). %TODO REFERENCIA!!

Los algoritmos~\ref{algoritmo:BestImprovement} y~\ref{algoritmo:FirstImprovement} se han obtenido directamente de Hansel et al.~\cite{vns} y describen el proceso asociado al \textit{Best Improvement} y al \textit{First Improvement} respectivamente.

\begin{algorithm}[htbp]
\caption{Best Improvement}
\label{algoritmo:BestImprovement}

\DontPrintSemicolon
\KwData{
$x$, solución actual.
}
\medskip

\Repeat{
	$f(x) \le f(x')$
}{
	$x' \leftarrow x$ \;
	$x \leftarrow \arg \max_{y \in N(x')} f(y)$ \;
}
\Return x \;

\end{algorithm}

\begin{algorithm}[htbp]
	\caption{First Improvement}
	\label{algoritmo:FirstImprovement}
	
	\DontPrintSemicolon
	\KwData{
		$x$, solución actual. 
	}
	\medskip
	
	\Repeat{
		$f(x) \le f(x')$
	}{
		$x' \leftarrow x$ \; 
		$i \leftarrow 0$ \;
		\Repeat{$f(x) > f(x')$ ó $i = |N(x)|$}{
			$i \leftarrow i + 1$ \;
			$x \leftarrow \arg \max \left\lbrace f(x), f(x^i)\right\rbrace $, $x^i \in N(x)$ \;
		}
	}
	\Return x \;
	
\end{algorithm}

Por el otro lado, la componente estocástica introduce en la búsqueda una solución generada de forma aleatoria, de manera que nueva información se introduce en el proceso de búsqueda que puede mejorar el valor de fitness empleando, por ejemplo fragmentos de aleatoria que de forma determinista nunca podrían haberse logrado o como mínimo habría sido necesario un mayor tiempo de cómputo. En el \autoref{algoritmo:Basic-VNS} se muestra el proceso esquemáticamente para el VNS Básico. Nótese que la condición de parada es únicamente el tiempo de cómputo, no obstante, se suele combinar con un porcentaje mínimo de mejoría de forma que si la búsqueda se estanca, no se pierda tiempo de cómputo innecesariamente. Las condiciones de parada del algoritmo se encuentran descritas en profundidad en la \autoref{apartado:condiciones-parada}.

\begin{algorithm}[htbp]
	\caption{Basic VNS~\cite{vns}}
	\label{algoritmo:Basic-VNS}
	
	\DontPrintSemicolon
	\KwData{
		
		$x$, solución actual. 
		
		$k_{max}$, número de entornos definidos para la metaheurística.
		
		$t_{max}$, tiempo máximo de ejecución del algoritmo.
	}

%	\medskip
	\bigskip
	
	$t \leftarrow 0$ \;
	
	\While{$t<t_{max}$}{
		
		\Repeat{
			$k = k_{max}$
		}{
			$x' \leftarrow \texttt{Shake}(x,k)$ \Comment{Componente estocástica}
			$x'' \leftarrow \texttt{FirstImprovement}(x')$ \Comment{Búsqueda local}
			$x,k \leftarrow \texttt{NeighbourhoodChange}(x,x'',k)$ \Comment{Cambio de vecindad}
		}
		$t \leftarrow \texttt{CpuTime}()$ \Comment{Medición del tiempo de ejecución}
	}

	\Return x \;
	
\end{algorithm}

Por supuesto, cada problema es diferente y se adapta mejor a un método u otro y es por eso que con el tiempo se han definido algunas variaciones de VNS básico y que reciben nombres diferentes. La forma más sencilla de variar el método es suprimir una de las dos componentes: si sustituimos la componente estocástica, dejando la búsqueda únicamente determinista tenemos el \textit{Variable Neighborhood Descendent} (VND); mientras que si la búsqueda es únicamente estocástica tenemos el \textit{Reduced Variable Neighborhood Search} (RVNS). Éste último es el menos costoso computacionalmente, sin embargo es el que menos información del problema emplea y su rendimiento suele ser peor que los demás. 

Otra posible variación se basa en  emplear una técnica distinta para la búsqueda local. Si por ejemplo empleamos otro VNS únicamente determinista, es decir un VND (descendent) en lugar de una búsqueda local simple, estaremos empleando un \textit{General VNS}.

Por último, existen otras variaciones que rompen con la estructura básica del VNS pero que se ha visto que dan buenos resultados para ciertos problemas,  mejorando las variaciones anteriores. Entre ellas, el \textit{Skewed VNS} (SVNS) definido en~\cite{svns-def} cuya idea se basa en explorar óptimos locales lejanos a óptimo actual, potenciando la exploración sobre la explotación intrínseca al propio VNS por definición. Así, podrá moverse entre soluciones peores con el fin de encontrar información reutilizable en la solución, sin embargo, la exploración de debe realizarse demasiado lejos de la solución actual, pues podría degenerar en una búsqueda de inicio múltiple (\textit{multistart}), donde se hacen búsquedas repetidamente empleando como solución de inicio una generada aleatoriamente, y ésto se sabe que es ineficiente para este tipo de problemas~\cite{vns}). Para evitar ésto, se define una función de distancia de forma que si la solución peor a explorar está demasiado lejos de la actual, se descarte.

Para ello, el SVNS define un parámetro adicional denotado normalmente como $\alpha$, que multiplica la función de distancia y es el que permite la exploración más o menos lejos de la solución actual. El \autoref{algoritmo:VNS-cambio-entornos} explicado previamente se redefine de la siguiente manera:

\begin{algorithm}[h]
	\caption{Redefinición del algoritmo de cambio de vecindades para un \textit{Skewed} VNS en un problema de maximización}
	\label{algoritmo:SVNS-cambio-entornos}
	
	\DontPrintSemicolon
	\KwData{
		
		$x$, solución actual. En la primera iteración es la inicial.
		
		$x'$, solución obtenida del algoritmo de búsqueda local con el entorno $k$
		
		$k$, indice de la vecindad actual
		
		$\alpha$, parámetro de la metaheurística
	}
	\bigskip
	
	\If{$f(x')+\alpha \cdot \rho(x,x') > f(x)$}{
		$x \leftarrow x'$ \Comment{Moverse a la mejor solucion}
		$k \leftarrow 1$  \Comment{Reinicio de vecindades}
	}
	\Else{
		$k \leftarrow k+1$ \Comment{Siguiente vecindad}
	}
	
\end{algorithm}

Donde $\rho(x,x')$ es la función de distancia definida para el problema concreto.

El algoritmo central del SVNS es homólogo al \autoref{algoritmo:Basic-VNS} con la diferencia de que debido a que el nuevo algoritmo de cambio de entorno no retorna la mejor solución, sino la próxima a explorar (de peor \textit{fitness} pero alejada de ella), debemos almacenar la mejor para no perderla, y actualizarla en cada iteración. Además, será la que devolvamos al final del algoritmo.

Existen más variaciones del algoritmo básico del VNS que no se han contemplado en éste proyecto, por lo que no se encuentran definidas aquí. Más información al respecto puede hallarse en~\cite{vns,info-adicional-vns}

\subsubsection{Adaptación del VNS al problema}
\label{apartado:adaptacion-VNS}

Una vez definida la técnica a utilizar y las posibles variaciones planteadas, debemos instanciar los parámetros del algoritmo y definir las heurísticas ---dependientes del problema concreto--- necesarias de la metaheurística.

En las próximas secciones se describe cómo se ha optado por adaptar la metaheurística descrita en la sección anterior al problema descrito en el \autoref{capitulo:2}: cómo se ha implementado la función de evaluación, qué entornos se han definido y bajo qué criterios son ordenados, las técnicas de exploración y explotación utilizadas y, finalmente, las condiciones de parada

La primera característica necesaria para las metaheurísticas ---y cualquier técnica, en palabras generales--- es la codificación (definida en la sección anterior). En el caso de nuestro problema, tal y como se describió detalladamente en la \autoref{apartado:representacion-soluciones}, las soluciones se representan de forma matricial con una discretización del tiempo a intervalos de 5 minutos. La representación desde el punto de vista de la programación se encuentra descrita en la \autoref{sec:detalles-impl-sistema}. % TODO ajustar referencia cruzada

\NOTE{poner los vns adaptados al problema (funciondistancia del skewed y demas cosas que no tienen apartado propio)}% TODO: 

\paragraph{Función Fitness} \label{apartado:adaptacion-fitness}

La función fitness tiene por objeto la evaluación de una solución de manera que se puedan comparar entre sí dos o más soluciones del problema y poder decidir cuál es la mejor.  Para poder definir una función de evaluación hacen falta uno o más \textit{objetivos} o \textit{criterios}. En caso de encontrar un único objetivo estaremos ante una búsqueda \textit{uniobjetivo}, mientras que si hay varios, sería \textit{multiobjetivo} o \textit{multicriterio}. En los problemas reales es habitual encontrarse con más de un criterio, algunos quizás contradictorios entre sí, por lo que aparece la figura del \textit{decisor}, que suele ser el cliente o el principal stakeholder del proyecto, y es el encargado de seleccionar aquellos objetivos que considere más relevantes (e incluso ponderarlos si es preciso) de esta forma se resuelven los conflictos entre objetivos. Otra opción para resolver ésto consiste en presentar al decisor un conjunto de soluciones y que este elija la que más le convenga en función de sus criterios. En nuestro caso, si bien podríamos haber optado por cualquiera de las dos decisiones, por razones históricas, se empleó la primera opción. 

Dentro de la primera opción, tenemos diferentes alternativas introducidas \hyperref[sec:3:metaheurística]{al principio de ésta sección}, que son: enfoques de escalarización, basados criterios, basados en dominaciones (óptimos de Pareto) entre las soluciones o basados en indicadores de calidad. Los más empleados son los primeros, pues aportan una mayor sencillez a la resolución del problema ya que permiten trasformar el problema multiobjetivo en uniobjetivo. Dicha transformación se puede realizar a su vez de diferentes maneras, como se puede apreciar en la \autoref{fig:enfoques-fitness-multiobj}, definidas en detalle en~\cite{sota:metaheuristicas-design-impl} entre otros. Nosotros hemos optado con el primero de todos, pues es el más sencillo y nos permite una mayor flexibilidad en caso de tener que modificar las prioridades de los objetivos en un futuro, sin necesidad de recalcular nada. El enfoque de escalarización mediante agregación construye la función fitness de la forma:

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{enfoques-resolucion-fitness-optimizacion-multiobj}
	\caption[Esquema de los posibles enfoques para la resolución del problema del fitness en optimización multiobjetivo]{Esquema de los posibles enfoques para la resolución del problema del fitness en optimización multiobjetivo. Obtenido de~\cite{sota:metaheuristicas-design-impl}}
	\label{fig:enfoques-fitness-multiobj}
\end{figure}

\[
	f(x) = \sum_{i=1}^{n} \lambda_i \cdot f_i(x) = \lambda_1 f_1(x) + \lambda_2 f_2(x) + \lambda_3 f_3(x) + \lambda_4 f_4(x) + \dots
\]

Donde $f_i(x)$ es la función objetivo $i$-ésima y $\lambda$ un escalar entre 0 y 1 de manera que $\sum_{i=1}^n \lambda_i = 1$

Cada función objetivo tiene asociado un escalar que pondera la relevancia de la función, de manera que nuestro decisor, los responsables del proyecto por parte de \gls{CRIDA}, deberá ponderar los objetivos según sus criterios. En éste caso, \gls{CRIDA} aún no ha ponderado los objetivos, pero sí nos ha proporcionado una lista de los mismos ordenada por importancia, de forma que podemos utilizar diferentes valores para los pesos (escalares) siempre y cuando respetemos el orden de relevancia del decisor. Los objetivos, ordenados del más prioritario al menos prioritario son:

\begin{enumerate}[label={O\arabic*}]
	\item \label{O1} Reducir el número de controladores: Si añadimos nuevos controladores imaginarios, debemos eliminarlos de forma que conservemos el número inicial y, si es posible, reducir el numero inicial de los mismos.
	
	\item \label{O2} Factibilidad de las soluciones: es importante que se cumplan los criterios del dominio del problema, pero debido a que se trata de una planificación de urgencia, el decisor lo considera menos importante que el objetivo anterior.
	
	\item \label{O3} Tras el momento en el que se sucede la incidencia, los cambios propuestos por nuestro sistema deberían ser \textit{suaves}, es decir, que el numero de cambios de sala de los controladores sea el menor posible.
	
	\item \label{O4} Cuanto más se parezca una solución del sistema a una plantilla mejor, pues los empleados están acostrumbrados a manejar este tipo de planificaciones ya que resultan más intuitivas.
\end{enumerate}

Cuatro objetivos que podemos ponderar de diferentes formas, entre los que encontramos: 

\begin{enumerate}[label=\alph*)]
	\item mismos pesos para todos los objetivos
	\item pesos del método Rank-Sum (RS)
	\item pesos del método \textit{Rank Order-Centroid} (ROC)
\end{enumerate}

La técnica que mejores resultados ofrece es el método ROC, una definición precisa y un estudio comparativo de éstas técnicas de ponderación de objetivos en problemas de decisión multi-criterio entre otras no nombradas, puede encontrarse en~\cite{ROC-comparativas-tecnicas}. \NOTE{ XQ ROC y no RS si en el paper es mejor RS?? } % TODO NOTE;

El método ROC utiliza la siguiente fórmula para la ponderación de cada objetivo $\lambda_i$ ordenados del más importante al menos importante:
\[
	\lambda_i = \sfrac{1}{N} \sum_{j=i}^N \frac{1}{j}
\]

De forma que calculamos todos los pesos $\lambda_i$ con $N=4$. Como podemos ver, suman $1$:

\begin{flalign*}
	& \lambda_1 =  \sfrac{1}{4} \sum_{j=1}^4 \frac{1}{j} = \frac{1}{4} \left( \frac{1}{1}+\frac{1}{2}+\frac{1}{3}+\frac{1}{4} \right) = 0.52 \\	
	&\lambda_2 =  \sfrac{1}{4} \sum_{j=2}^4 \frac{1}{j} = \frac{1}{4} \left( \frac{1}{2}+\frac{1}{3}+\frac{1}{4} \right) = 0.27 \\
	&\lambda_3 =  \sfrac{1}{4} \sum_{j=3}^4 \frac{1}{j} = \frac{1}{4} \left( \frac{1}{3}+\frac{1}{4} \right) = 0.15 \\
	&\lambda_4 =  \sfrac{1}{4} \sum_{j=4}^4 \frac{1}{j} = \frac{1}{4} \left( \frac{1}{4} \right) = 0.06 
\end{flalign*}

Tres de las definiciones de las funciones objetivo han sido reutilizadas de diferentes partes del del sistema \legacy{} (objetivos~\ref{O1},~\ref{O2} y~\ref{O3}). Esto es así debido a que, tal y como se detalló en el \autoref{capitulo:2:detalles-sistema}, el sistema \legacy{} también realizaba una optimización multi-criterio que, debido a la ausencia de urgencia temporal de ejecución, el número de funciones objetivo era considerablemente mayor. En nuestro caso se han tomado aquellos objetivos decisivos para el sistema, aunando objetivos de diferentes fases de la metodología propuesta en el sistema \legacy{}. Véase~\cite{articulo1} para una mayor descripción tanto de la metodología \legacy{} como todas las funciones objetivo planteadas entonces, especialmente la normalización de las mismas, que se ha optado por no incluir aquí.

Adicionalmente se ha creado un nuevo objetivo,~\ref{O4}, nacido de las nuevas características del presente sistema: el momento del cambio.


La función objetivo final, empleando el método de escalarización ponderada tiene esta forma:
\[
	f(x)= 
%	\left\{ 
	\begin{cases}
		\lambda_1 f_1(x) + \lambda_2 f_2(x) + \lambda_3 f_3(x) + \lambda_4 f_4(x) & \quad \textrm{si } \, nATC > nATCdisp  \\
		\\
%		                                                                          &    &                   \\
		\lambda_2 f_2(x) + \lambda_3 f_3(x) + \lambda_4 f_4(x)                    & \quad \textrm{si } \,  nATC \le nATCdisp
	\end{cases}
%   \right.	
\]

Donde $nATC$ es el número de controladores aéreos (\gls{ATC}) empleados en la solución actual ($x$) y $nATCdisp$ es el numero de controladores disponible para esa instancia del problema. La idea es que el primer número sea igual o menor al primero, de esta forma la solución podrá llevarse a cabo sin necesidad de buscar controladores extra. Como ya se ha dicho previamente, el problema de optimización se expresará en forma de maximización de la expresión.

Se ha definido así debido a que cuando el valor de la primera función objetivo alcanza su máximo valor (uno), ya no aporta nada al sistema, y podemos ahorrarnos un tiempo significativo de cómputo, pues el cálculo de cada una de ellas es costoso (véase \NOTE{Gráfica tiempo ejecución de cada parte del sistema. Comparación usando todos los fitness vs el primero no???}).%TODO hacer grafica y ponerla en implementacion

Para poder emplear este modelo de escalarización aditivo, todas las funciones objetivo se han normalizado, de esta forma las escalas manejadas por cada uno de ellos son las mismas y puedan ser añadidos al sumatorio ponderado.

A continuación describiremos brevemente cada una de estas funciones.

La primera función objetivo~\ref{O1} tiene la siguiente fórmula:
\[ f_1 = \frac{1}{nATC^2} \sum_{i=1}^c i\cdot h_i \]
Donde $nATC$ es el número de controladores aéreos empleados en la solución actual ($x$) y $h_i$ es el número de slots en los que el $i$-ésimo controlador está trabajando. La componente $\sfrac{1}{nATC^2}$ garantiza al algoritmo que siempre merezca la pena eliminar un controlador. El resto de la expresión orienta la metaheurística para que mueva carga de los controladores de la parte superior de la matriz hacia índices inferiores, acumulando carga hacia abajo permitiendo que los controladores superiores ---los imaginarios--- se queden sin carga y puedan ser eliminados (véase \autoref{apartado:representacion-soluciones}).

La segunda función objetivo~\ref{O2} tratará de minimizar\footnote{En realidad la expresión se transforma en términos de maximización pero la esencia es esa.} el número de restricciones del dominio incumplidas ---definidas en el Apartado Implementación requisitos de dominio (entorno)---, %TODO referencia!!
favoreciendo la factibilidad de la solución alcanzada. Su implementación cuenta el número de restricciones incumplidas (normalizado). 

En caso de que el trabajador tenga slots fuera de turno (véase \autoref{sec:baja-alta-controladores}) éstos serán contabilizados como descansos para que en aquellos controladores que llegan como sustitutos en momentos finales de la planificación se tenga en cuenta que no han estado trabajando y el porcentaje de descanso mínimo (Requisito XXX) % TODO referencia!!
tenga un valor coherente con la realidad.

En nuestra implementación, para ahorrar tiempo de cómputo, el conteo de las restricciones incumplidas se realiza en paralelo, aprovechando la capacidad de computación multihilo del ordenador de trabajo. (véase ...) % TODO referencia!

La tercera función objetivo~\ref{O3}, implementada por vez primera para éste sistema, trata de minimizar el número de cambios en sala al momento de producirse la incidencia. Esto es debido a que cuanto menos se muevan los trabajadores de su puesto, mejor eficiente y rápido prodrá realizarse la transición desde la planificación previa (la parte inamovible de la planificación, a la izquierda del momento del cambio) y la nueva (la creada por el sistema, a partir del momento del cambio).

Para contar el número de cambios simplemente tendremos que recorrer la matriz por la columna del momento del cambio, el índice $slot_{actual}$ y compararla con la columna anterior $slot_{actual}-1$, matemáticamente lo podríamos expresar como:

\[
	f_3(x) = \frac{1}{nATC} \sum_{i=1}^{nATC} 
	\begin{cases}
		1 & \quad \textrm{si } x_i^{slot_{cambio}} = x_i^{slot_{cambio}-1} \\
		0 & \quad \textrm{en otro caso }
	\end{cases}
\]


%\[
%	f_3(x) = \frac{1}{nATC} \sum_{i=1}^{nATC} t_i
%	\; , \quad \textrm{con } t_i = \begin{cases}
%		1 & \quad \textrm{si } x_i^{slot_{actual}} = x_i^{slot_{actual}-1} \\
%		0 & \quad \textrm{en otro caso }
%	\end{cases}
%\]

Con $x_i^j$ el sector y la posición asignados por la solución $x$ al controlador $i$ (fila) en el slot $j$ (columna). Consideramos un cambio tanto cuando el sector es diferente como cuando lo es la posición, aunque sea el mismo sector.
El quebrado $\sfrac{1}{nATC}$ sirve para normalizar la función, y poder usarla junto con todas las demás. 

La cuarta y última función objetivo~\ref{O4}, trata de lograr que las planificaciones resultantes sean parecidas a los estadillos (definidos en el \autoref{sec:3:inicializacion-soluciones}). Lo lograremos comparando para slot de la solución el sector asignado con aquél del slot inmediatamente a la derecha y aquel inmediatamente inferior. Matemáticamente de la siguiente forma:

\[
	f_4(x) = \sum_{i=1}^{nATC} \sum_{i=1}^{nSlots}
	\begin{cases}
		1 & \; \textrm{si } \; x_i^j = x_{i+1}^{j} \\
													\\
		1 & \; \textrm{si } \; x_i^j = x_{i}^{j+1}   \\
													  \\
		0 & \; \textrm{en otro caso }  \NOTE{\textrm{HACE FALTA ESTE? LO QUITO??}}
	\end{cases}
\]

Con $nSlots$ en número de slots de la instancia concreta del problema. Cabe destacar que, en caso de alcanzar slots
donde no sea posible comparar con posiciones inmediatamente inferior o derecha debido a que se alcance el final de la matriz, entonces dicho caso será ignorado.

\paragraph{Definicion de entornos}
En secciones previas se ha introducido el concepto de entorno: estructuras algorítmicas de manipulación de una solución que permiten moverse hacia otras cercanas. Por lo tanto, definen el criterio a emplear para moverse entre soluciones.

Para definir un entorno, necesitamos conocer la representación de las soluciones (recuérdese la \autoref{apartado:representacion-soluciones}), pues en función de la misma definiremos los entornos. En nuestro caso, se trata de una representación discreta en forma matricial. Para este tipo de representaciones lo mas habitual es la permutación de elementos de la solución para transformarlas en otras.

Los antecedentes respecto a las definiciones de entorno no son demasiados, Jónatan Lara Valero realizó un estudio exhaustivo desde el punto de vista matemático de los entornos del sistema \legacy{} y propuso uno nuevo con una técnica innovadora de rejilla. En su tesis, Lara describe y analiza el comportamiento de los entornos definidos por Tello et al. en~\cite{articulo1} denominados como \textit{mov3} y \textit{mov6}. 

El primer movimiento, \textit{mov3}, se define algorítmicamente de la forma indicada en el \autoref{algoritmo:entorno-mov3}. Como podemos ver, consiste en probar todas las posibles combinaciones de controladores y longitudes hasta encontrar una combinación que nos permita realizar el cambio.

\begin{algorithm}[h]
	\caption{Movimiento \textit{mov3}}
%	\algorithmicgoto~\ref{testtt}
	\label{algoritmo:entorno-mov3}
	
	\SetAlgoNoLine
	\SetAlgoNoEnd
	\DontPrintSemicolon
	\LinesNumbered
%	\setstretch{1.35}
%	\setlength{\parskip}{0.4ex}
	
	\KwIn{
		
		$s$, una solución
%		$d$, índice de la solución inicial
	}
	\bigskip
	
%	\Repeat{no queden controladores por probar}{
%		Seleccionar un controlador $c_1$ aleatoriamente \;
%		Elegir un periodo de trabajo de $c_1$ aleatoriamente \label{testtt} \;
%	}

	Seleccionar un controlador $c_1$ aleatoriamente \; \label{line:c1}
	\algovspace
		
	Obtener lista de los periodos de trabajo continuados $L_{c_1}$
	\algovspace
		
	Elegir un periodo de trabajo de $L_{c_1}$ aleatoriamente \label{line:3} \;
	\algovspace
		
	Generar lista de amplitudes mediante múltiplos del tamaño del descanso. En nuestro sistema siempre es de 6 (véase la \autoref{capitulo:3:paso-2}), por lo que sería: $\left\lbrace 3,6,9,12\right\rbrace $ \;
	\algovspace
		
	Seleccionar una amplitud (granularidad) $d$ aleatoriamente de entre la lista \label{line:amplitud}\;
	\algovspace
		
	Seleccionar los $d$ primeros slots del periodo de trabajo $L_{c_1}$ seleccionado en el \algorefpaso{line:3}\; % paso(\ref{line:3})
	\algovspace
	
	Elegir aleatoriamente otro controlador $c_2$ \label{line:c2}\;
	\algovspace
	
	\leIf{se puede realizar el cambio de carga $L_{c_1}$ de $c_1$ a $c_2$}
	{hacer el cambio y \textbf{fin}, }
	{se elige otro $c_2$ aleatoriamente (sin repreticiones), volviendo al \algorefpaso{line:c2}}
	\algovspace
	
	\lIf{ningun $c_2$ admite la carga de $c_1$}{elegir otra amplitud $d$, volviendo así al \algorefpaso{line:amplitud}} %paso (\autoref{line:amplitud})}
	\algovspace
	
	\lIf{ninguna amplitud permite un cambio válido}{elegir otro controlador $c_1$, volviendo al \algorefpaso{line:c1}} % paso (\ref{line:c1})}
	\algovspace
	
	\lIf{aun así no es posible en ninguna combinación}{\Return $\emptyset$}
	\algovspace	
\end{algorithm}


El movimiento \textit{mov6} consiste simplemente en la repetición del anterior dos veces para potenciar la capacidad exploratoria del sistema.

Lara en su tesis propone además los movimientos en una o varias rejillas, que tratan de mantener la estructura vertical que tienen las soluciones debido a los patrones regulares que presentan los estadillos empleados para definir la solución inicial:

\begin{quotation} {\itshape
%	Los movimientos en rejilla parten de un idea básica: mantener la estructura
%	vertical de las soluciones iniciales. [...] La construcción de las soluciones iniciales a partir de plantillas hace que tengan ciertas regularidades La estructura vertical es esta regularidad. +
%	Los cambios en las asignaciones se hacen con regularidad y solo la sectorización puede romper esta regularidad.
	
	<<Los movimientos \textit{mov3} y \textit{mov6} rompen la estructura vertical de las soluciones
	iniciales salvo que las amplitudes, la longitud de los descansos y la sectorización sean
	compatibles entre sí, caso que no se dá en muchas situaciones.
	
	Para solventar este problema definimos el movimiento \textit{mov12}. En este movimiento,
	se crea una rejilla a partir de la solución inicial que limita los intercambios
	que pueden hacerse entre controladores. Una rejilla no será más que una serie de
	puntos que dividirán el turno en intervalos, no necesariamente iguales en tamaño. El
	movimiento \textit{mov12} consistirá siempre en intercambiar uno de estos intervalos entre
	dos controladores.>>}
	\rightline{---Jónatan Lara Valero~\cite{tesis-jonatan}}
\end{quotation}

A su vez propone otros movimientos como variaciones de este, pero para esta tesis únicamente hemos considerado su propuesta del uso de rejillas simple como un tipo de entornos que hemos definido. Este tipo de entornos limitan los intercambios de carga de trabajo permitidos a unas franjas de intervalos concretas. Véase la \autoref{fig:representacion-rejilla} para comprender visualmente cómo se constituye una rejilla a partir de una solución.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{representacion-rejilla}
	\caption[Representación gráfica de una rejilla]{Representación gráfica de una rejilla. Fuente:~\cite{tesis-jonatan}}
	\label{fig:representacion-rejilla}
\end{figure}

Si bien no forma parte de esta tesis, pues no se trata de trabajo propio, debido a que en el \autoref{capitulo:5} se hacen comparaciones entre las dos metaheurísticas definidas, consideramos importante en esta sección destacar que, los entornos definidos para el sistema \legacy{} ---los aquí definidos, entre otros--- fueron actualizados siguiendo las restricciones de codificación (véase XXX) % TODO: REFERENCIA Y TODO ESO!!!
y el \gls{SA} fue ejecutado empleando todos ellos. El estudio concluyó con que el entorno que mejores resultados ofrecía para el SA es el \textit{mov15}, uno de los propuestos por Lara en~\cite{tesis-jonatan}, de tipo rejilla con la variación de que permite intercambiar más de un intervalo a la vez, entre 1 y 3 siempre y cuando estén consecutivos.
% TODO: poner o referenciar en el capitulo 5!!!

Por otro lado, para el sistema \legacy{} también se desarrolló un VNS previamente: Pablo Lozano Santiuste propuso unas estructuras de entornos que intercambiaban carga a nivel de slot, repitiéndose sucesivas veces hasta que no fuese posible realizar el cambio, de esta forma se intercambiaría toda la carga posible de los dos controladores seleccionados aleatoriamente. Lozano en su tesis~\cite{tesis-pablo} emplea 4 tipos de entornos cuyas diferencias residen en las restricciones de entorno de cada una: para poder realizar el cambio o bien es necesario que el primero trabaje y en segundo descanse o bien que ambos trabajen. Y otros dos equivalentes pero con la restricción adicional de que el trabajo segundo controlador sea en el mismo sector que el primero previamente, de forma que se continúe el trabajo.


Para este proyecto se han empleado ideas de todos ellos y se han definido tres tipos de entornos, cada uno con un principio diferente:
\begin{itemize}
	\item \textbf{Movimientos de máxima carga} \textit{(movMaxCarga)}: se basa en el traspaso de la mayor carga posible de trabajo entre los controladores
	
	\item \textbf{Movimientos en rejilla} \textit{(movRejilla)}: permite el traspaso de carga sin romper la estructura de la solución
			
	\item \textbf{Movimiento libr}e \textit{(movLibre)}: si no es posible un intercambio mediante ninguno de los anteriores, trataremos de tomar intervalos más pequeños de carga
\end{itemize}

Como podemos ver, los dos primeros no tienen libertades de movimiento, sino que deberán mover un numero de slots concreto, nunca menor que la carga continuada o la sección limitada por la rejilla. Para no limitar el espacio de soluciones, añadimos el último, que permite esa libertad en cuanto al tamaño. A continuación describiremos cada uno de ellos.

La idea inicial consiste en emplearlos en el orden descrito, de forma que primero se quite la máxima carga del controlador superior y si no es posible, se utilicen rejillas, y finalmente sin restricciones de entorno. No obstante, empirícamente descubrimos que ésto no era lo óptimo, tal y como se ha indicado en el \autoref{capitulo:5}.

\subparagraph{Movimientos de máxima carga}
\textbf{Objetivo:} Intentar pasar toda la carga de trabajo continuado.

\textbf{Comportamiento:} Se intenta pasar toda la máxima carga posible de trabajo de $c_1$ a $c_2$

\textbf{Algoritmo:}
\RestyleAlgo{plain}
\SetAlgoNoLine
\LinesNumbered
\SetAlgoNoEnd
\DontPrintSemicolon
\begin{algorithm}[h]
	\label{algoritmo:movMaxCarga}
	\SetAlgoNoEnd
	Se elige arbitrariamente un controlador $c_1$ (en caso de existir algún imaginario, en lugar de arbitrariamente, se toma en orden partiendo del primer imaginario) \label{line:maxcarga:paso1}\;
	\algovspace
	
	Obtener los intervalos de trabajo continuo de $c_1$\;
	\algovspace
	
	Elegir un intervalo de trabajo aleatoriamente \label{line:maxcarga:trabajo}\;
	\algovspace
	
	Elegir arbitrariamente un controlador $c_2$ \label{line:maxcarga:c2}\;
	\algovspace
	
	\If{se cumplen las restricciones del dominio (en especial que la acreditación sea válida %TODO referencia al requisito concreto
		)o y del entorno \label{line:maxcarga:restricciones}}{traspasar carga y \textbf{fin}}
%	\footnote{Es decir, que ambos trabajadores estén acreditados para llevar a cabo el trabajo del otro controlador}
	\algovspace
	
	\textbf{en caso de\,} \underline{no se cumplirse alguna restricción}, probar con otro $c_2$ volviendo al \autoref{line:maxcarga:c2}\;
	\algovspace
	
	\textbf{en caso de\,} \underline{haber probado todos los $c_2$}, tomar otro intervalo de trabajo y volver al \autoref{line:maxcarga:trabajo}\;
	\algovspace
	
	\textbf{en caso de\,} \underline{haber probado todos los intervalos de trabajo}, volver al \autoref{line:maxcarga:paso1} hasta probar todos los $c_1$\;
	\algovspace
\end{algorithm}

\textbf{Restricciones de entorno (y nombre):}
\begin{enumerate}[align=parleft, labelsep=2cm, itemindent=5em, font=\itshape]
	\item[MovMaxCarga]\mbox{}\\No hay restricciones
	
	\item[MovMaxCarga\_1]\mbox{}\\
		$c_1$ debe tener trabajo en el intervalo elegido \\ 
		$c_2$ debe estar descansando en el intervalo elegido
	
	\item[MovMaxCarga\_2]\mbox{}\\
		$c_1$ debe tener trabajo en el intervalo elegido \\ 
		$c_2$ debe estar trabajando en el intervalo elegido \\
		El sector y la posición de trabajo de $c_1$ deberán ser la misma que la de $c_2$

	\item[MovMaxCarga\_3]\mbox{}\\
		$c_1$ debe tener trabajo en el intervalo elegido \\ 
		$c_2$ debe estar descansando en el intervalo elegido \\
		El sector de $c_1$ deberá ser el mismo que el de $c_2$, pero la posición del trabajo no tiene por qué

	\item[MovMaxCarga\_4]\mbox{}\\
		$c_1$ debe tener trabajo en el intervalo elegido \\ 
		$c_2$ debe estar descansando en el intervalo elegido \\
		El sector y la posición de trabajo podrán ser diferentes 
\end{enumerate}

\paragraph{Búsqueda diversificada/intensificada} \label{capitulo:3:busqueda-divers-intens}
Lorem ipsum

\paragraph{Condiciones de Parada}
\label{apartado:condiciones-parada}
Lorem ipsum










